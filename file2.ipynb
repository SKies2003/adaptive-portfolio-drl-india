{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb265c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import random\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import quantstats as qs\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc578e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined list without duplicates: ['BAJFINANCE.NS', 'TECHM.NS', 'JIOFIN.NS', 'Eternal.NS', 'BEL.NS', 'HDFCBANK.NS', 'TCS.NS', 'ADANIPORTS.NS', 'ICICIBANK.NS', 'HCLTECH.NS', 'SHRIRAMFIN.NS', 'SBIN.NS', 'SBILIFE.NS', 'TATAMOTORS.NS', 'COALINDIA.NS', 'RELIANCE.NS', 'POWERGRID.NS', 'INFY.NS', 'KOTAKBANK.NS', 'GRASIM.NS', 'ONGC.NS', 'BHARTIARTL.NS', 'LT.NS', 'AXISBANK.NS', 'TRENT.NS', 'APOLLOHOSP.NS', 'NESTLEIND.NS', 'TITAN.NS', 'HDFCLIFE.NS', 'BAJAJ-AUTO.NS', 'JSWSTEEL.NS', 'HINDUNILVR.NS', 'MARUTI.NS', 'DRREDDY.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'ASIANPAINT.NS', 'INDUSINDBK.NS', 'TATASTEEL.NS', 'ADANIENT.NS', 'WIPRO.NS', 'ULTRACEMCO.NS', 'TATACONSUM.NS', 'ITC.NS', 'M&M.NS', 'SUNPHARMA.NS', 'EICHERMOT.NS', 'CIPLA.NS', 'BAJAJFINSV.NS', 'NTPC.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ETERNAL.NS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2014-04-01 00:00:00 -> 2025-03-31 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1396290600, endDate = 1743359400\")')\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:54: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:68: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_df = yf.download(Tickers, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers with complete data: ['BAJFINANCE.NS', 'TECHM.NS', 'BEL.NS', 'HDFCBANK.NS', 'TCS.NS', 'ADANIPORTS.NS', 'ICICIBANK.NS', 'HCLTECH.NS', 'SHRIRAMFIN.NS', 'SBIN.NS', 'TATAMOTORS.NS', 'COALINDIA.NS', 'RELIANCE.NS', 'POWERGRID.NS', 'INFY.NS', 'KOTAKBANK.NS', 'GRASIM.NS', 'ONGC.NS', 'BHARTIARTL.NS', 'LT.NS', 'AXISBANK.NS', 'TRENT.NS', 'APOLLOHOSP.NS', 'NESTLEIND.NS', 'TITAN.NS', 'BAJAJ-AUTO.NS', 'JSWSTEEL.NS', 'HINDUNILVR.NS', 'MARUTI.NS', 'DRREDDY.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'ASIANPAINT.NS', 'INDUSINDBK.NS', 'TATASTEEL.NS', 'ADANIENT.NS', 'WIPRO.NS', 'ULTRACEMCO.NS', 'TATACONSUM.NS', 'ITC.NS', 'M&M.NS', 'SUNPHARMA.NS', 'EICHERMOT.NS', 'CIPLA.NS', 'BAJAJFINSV.NS', 'NTPC.NS']\n",
      " you have 46 mix stocks in your portfolio.\n",
      "Ticker\n",
      "ADANIENT.NS      0.533033\n",
      "SHRIRAMFIN.NS    0.430222\n",
      "TATAMOTORS.NS    0.409387\n",
      "INDUSINDBK.NS    0.402556\n",
      "HINDALCO.NS      0.393939\n",
      "ADANIPORTS.NS    0.384702\n",
      "BEL.NS           0.376907\n",
      "TATASTEEL.NS     0.363614\n",
      "BAJFINANCE.NS    0.360796\n",
      "TRENT.NS         0.350689\n",
      "ONGC.NS          0.341258\n",
      "JSWSTEEL.NS      0.338239\n",
      "SBIN.NS          0.334997\n",
      "AXISBANK.NS      0.330633\n",
      "BAJAJFINSV.NS    0.330546\n",
      "APOLLOHOSP.NS    0.321273\n",
      "EICHERMOT.NS     0.320266\n",
      "ICICIBANK.NS     0.309528\n",
      "M&M.NS           0.303629\n",
      "TATACONSUM.NS    0.303308\n",
      "TITAN.NS         0.302612\n",
      "COALINDIA.NS     0.298433\n",
      "BHARTIARTL.NS    0.296008\n",
      "TECHM.NS         0.291060\n",
      "SUNPHARMA.NS     0.289373\n",
      "GRASIM.NS        0.288964\n",
      "HEROMOTOCO.NS    0.277078\n",
      "MARUTI.NS        0.274435\n",
      "RELIANCE.NS      0.273687\n",
      "ULTRACEMCO.NS    0.272467\n",
      "LT.NS            0.271681\n",
      "NTPC.NS          0.269172\n",
      "HCLTECH.NS       0.269157\n",
      "DRREDDY.NS       0.266921\n",
      "INFY.NS          0.265045\n",
      "CIPLA.NS         0.264843\n",
      "KOTAKBANK.NS     0.264643\n",
      "WIPRO.NS         0.257112\n",
      "BAJAJ-AUTO.NS    0.254685\n",
      "POWERGRID.NS     0.253497\n",
      "ASIANPAINT.NS    0.253301\n",
      "ITC.NS           0.249863\n",
      "TCS.NS           0.235876\n",
      "NESTLEIND.NS     0.230409\n",
      "HINDUNILVR.NS    0.225516\n",
      "HDFCBANK.NS      0.223837\n",
      "dtype: float64\n",
      "Normalized indicators shape: (2700, 1)\n",
      "Normalized indicators shape: (2720, 1)\n",
      "Normalized nsei shape: (2700, 1)\n",
      "Normalized VIX shape: (2720, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:79: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  nsei_df=yf.download(\"^NSEI\", start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_9472\\585011713.py:101: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock_data = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "Normalized indicators shape: (46, 2711)\n",
      "macd shape: (46, 2711)\n",
      "rsi shape: (46, 2711)\n",
      "cci shape: (46, 2711)\n",
      "adx shape: (46, 2711)\n",
      "stoch shape: (46, 2711)\n",
      "willr shape: (46, 2711)\n",
      "bb_upper shape: (46, 2711)\n",
      "bb_middle shape: (46, 2711)\n",
      "bb_lower shape: (46, 2711)\n",
      "mfi shape: (46, 2711)\n",
      "ema shape: (46, 2711)\n",
      "atr shape: (46, 2711)\n",
      "sar shape: (46, 2711)\n",
      "obv shape: (46, 2711)\n",
      "Normalized indicators shape: (2700, 1)\n",
      "Normalized indicators shape: (2720, 1)\n",
      "Calculated state dimension: 694\n"
     ]
    }
   ],
   "source": [
    "start_train = dt.datetime(2014, 4, 1)\n",
    "end_train = dt.datetime(2022, 9, 30)\n",
    "start_test = dt.datetime(2022, 10, 1)\n",
    "end_test = dt.datetime(2025, 3, 31)\n",
    "\n",
    "start = start_train\n",
    "end = end_test  \n",
    "\n",
    "# stocks from NIFTY50 divided into their respective industry\n",
    "oil_gas_stocks = ['RELIANCE.NS', 'COALINDIA.NS','ONGC.NS']\n",
    "power_stocks = ['NTPC.NS', 'POWERGRID.NS']\n",
    "technology_stocks = ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS', 'TECHM.NS']\n",
    "fmcg_stocks = ['HINDUNILVR.NS', 'ITC.NS', 'TATACONSUM.NS', 'NESTLEIND.NS']\n",
    "healthcare_stocks = ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'APOLLOHOSP.NS']\n",
    "financial_stocks = ['HDFCLIFE.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'SBILIFE.NS', 'ICICIBANK.NS', 'AXISBANK.NS', 'HDFCBANK.NS', 'INDUSINDBK.NS', 'JIOFIN.NS', 'KOTAKBANK.NS', 'SHRIRAMFIN.NS', 'SBIN.NS']\n",
    "materials_stocks = ['ULTRACEMCO.NS', 'GRASIM.NS']\n",
    "auto_stocks = ['MARUTI.NS', 'EICHERMOT.NS', 'TATAMOTORS.NS', 'BAJAJ-AUTO.NS', 'HEROMOTOCO.NS', 'M&M.NS']\n",
    "capital_goods_stocks = ['BEL.NS']\n",
    "construction_stocks = ['LT.NS']\n",
    "consumer_durables_stocks = ['ASIANPAINT.NS', 'TITAN.NS']\n",
    "consumer_services_stocks = ['Eternal.NS', 'TRENT.NS']\n",
    "metal_mining_stocks = ['ADANIENT.NS', 'HINDALCO.NS', 'JSWSTEEL.NS', 'TATASTEEL.NS']\n",
    "services_stocks = ['ADANIPORTS.NS']\n",
    "telecomm_stocks = ['BHARTIARTL.NS']\n",
    "\n",
    "# Discard stock duplicate:\n",
    "combined_stocks = list(set(\n",
    "    oil_gas_stocks +\n",
    "    power_stocks +\n",
    "    technology_stocks +\n",
    "    fmcg_stocks +\n",
    "    healthcare_stocks +\n",
    "    financial_stocks +\n",
    "    materials_stocks +\n",
    "    auto_stocks +\n",
    "    capital_goods_stocks +\n",
    "    construction_stocks +\n",
    "    consumer_durables_stocks +\n",
    "    consumer_services_stocks +\n",
    "    metal_mining_stocks +\n",
    "    services_stocks +\n",
    "    telecomm_stocks\n",
    "))\n",
    "\n",
    "print(\"Combined list without duplicates:\", combined_stocks)\n",
    "\n",
    "# Create a list to store tickers with complete data:\n",
    "valid_stocks = []\n",
    "\n",
    "# Define the expected number of business days in the date range\n",
    "trading_days = pd.date_range(start=start, end=end, freq='B')\n",
    "\n",
    "for ticker in combined_stocks:\n",
    "    data = yf.download(ticker, start=start, end=end)\n",
    "    # Reindex the data to include all business days within the date range\n",
    "    data = data.reindex(trading_days, method='ffill').dropna()\n",
    "    # Check if the length of the data matches the number of trading days\n",
    "    if len(data) == len(trading_days):\n",
    "        valid_stocks.append(ticker)\n",
    "\n",
    "print(\"Tickers with complete data:\", valid_stocks)\n",
    "# Load stocks with complete data:\n",
    "\n",
    "print(f\" you have {len(valid_stocks)} mix stocks in your portfolio.\")\n",
    "Tickers=valid_stocks\n",
    "\n",
    "# Load data for valid_stocks:\n",
    "stock_df = yf.download(Tickers, start=start, end=end, progress=False)\n",
    "returns=stock_df['Close'].pct_change().dropna()\n",
    "\n",
    "# Calculate the standard deviation of daily returns for each stock\n",
    "volatility = returns.std()*np.sqrt(252)\n",
    "\n",
    "# Sort the stocks by their volatility in descending order:\n",
    "sorted_volatility = volatility.sort_values(ascending=False)\n",
    "print( sorted_volatility)\n",
    "\n",
    "# Add market features:\n",
    "nsei_df=yf.download(\"^NSEI\", start=start, end=end, progress=False)\n",
    "vix_df=pd.read_csv(r\"Data\\India_Vix.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Add technical indicators as features:\n",
    "def calculate_indicators(tickers, start, end):\n",
    "    macd = []\n",
    "    rsi = []\n",
    "    cci = []\n",
    "    adx = []\n",
    "    stoch = []\n",
    "    willr = []\n",
    "    bb_upper = []\n",
    "    bb_middle = []\n",
    "    bb_lower = []\n",
    "    mfi = []\n",
    "    ema = []\n",
    "    atr = []\n",
    "    sar = []\n",
    "    obv = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock_data = yf.download(ticker, start=start, end=end, progress=False)\n",
    "\n",
    "            close_prices = stock_data['Close'].astype(np.float64).values.flatten()\n",
    "            high_prices = stock_data['High'].astype(np.float64).values.flatten()\n",
    "            low_prices = stock_data['Low'].astype(np.float64).values.flatten()\n",
    "            volume = stock_data['Volume'].astype(np.float64).values.flatten()\n",
    "\n",
    "            if close_prices.ndim > 1:\n",
    "                close_prices = close_prices.flatten()\n",
    "            if high_prices.ndim > 1:\n",
    "                high_prices = high_prices.flatten()\n",
    "            if low_prices.ndim > 1:\n",
    "                low_prices = low_prices.flatten()\n",
    "            if volume.ndim > 1:\n",
    "                volume = volume.flatten()\n",
    "\n",
    "            macd.append(ta.MACD(close_prices)[0])\n",
    "            rsi.append(ta.RSI(close_prices))\n",
    "            cci.append(ta.CCI(high_prices, low_prices, close_prices))\n",
    "            adx.append(ta.ADX(high_prices, low_prices, close_prices))\n",
    "            stoch_k, stoch_d = ta.STOCH(high_prices, low_prices, close_prices)\n",
    "            stoch.append(stoch_k)  # Assuming you want to append %K line of Stochastic\n",
    "            willr.append(ta.WILLR(high_prices, low_prices, close_prices))\n",
    "            bb_upper_ticker, bb_middle_ticker, bb_lower_ticker = ta.BBANDS(close_prices)\n",
    "            bb_upper.append(bb_upper_ticker)\n",
    "            bb_middle.append(bb_middle_ticker)\n",
    "            bb_lower.append(bb_lower_ticker)\n",
    "            ema.append(ta.EMA(close_prices))\n",
    "            atr.append(ta.ATR(high_prices, low_prices, close_prices))\n",
    "            sar.append(ta.SAR(high_prices, low_prices ))\n",
    "            obv.append(ta.OBV(close_prices, volume))\n",
    "\n",
    "            # Calculate the Money Flow Index (MFI)\n",
    "            mfi.append(ta.MFI(high=high_prices, low=low_prices, close=close_prices, volume=volume))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for {ticker}: {e}\")\n",
    "\n",
    "    return np.array(macd), np.array(rsi), np.array(cci), np.array(adx), np.array(stoch), np.array(willr), np.array(bb_upper), np.array(bb_middle), np.array(bb_lower), np.array(mfi), np.array(ema), np.array(atr), np.array(sar), np.array(obv)\n",
    "\n",
    "\n",
    "# Function to handle NaNs\n",
    "def handle_nans(indicators, fill_value=0):\n",
    "    inds_nan = np.isnan(indicators)\n",
    "    if inds_nan.any():\n",
    "        indicators = np.where(inds_nan, fill_value, indicators)\n",
    "    return indicators\n",
    "\n",
    "# Function to normalize indicators:\n",
    "def normalize_indicators(indicators):\n",
    "    indicators = handle_nans(indicators)  # Handle NaNs before normalization\n",
    "    if indicators.ndim == 1:\n",
    "        indicators = indicators.reshape(-1, 1)  # Reshape 1D array to 2D array\n",
    "\n",
    "    min_val = np.min(indicators, axis=1, keepdims=True)\n",
    "    max_val = np.max(indicators, axis=1, keepdims=True)\n",
    "\n",
    "    # Avoid divide-by-zero error by adding a small epsilon\n",
    "    epsilon = 1e-8\n",
    "    normalized = (indicators - min_val) / (max_val - min_val + epsilon)\n",
    "\n",
    "    print(f\"Normalized indicators shape: {normalized.shape}\")\n",
    "    return normalized\n",
    "\n",
    "# Normalize nsei and VIX :\n",
    "normalized_nsei = normalize_indicators(nsei_df['Close'].values)\n",
    "normalized_vix = normalize_indicators(vix_df['Close'].values)\n",
    "print(f\"Normalized nsei shape: {normalized_nsei.shape}\")\n",
    "print(f\"Normalized VIX shape: {normalized_vix.shape}\")\n",
    "\n",
    "indicators = calculate_indicators(Tickers, start, end)\n",
    "\n",
    "# Normalize indicators and store them in a dictionary:\n",
    "\n",
    "normalized_indicators = {}\n",
    "indicator_names = ['macd', 'rsi', 'cci', 'adx', 'stoch', 'willr', 'bb_upper', 'bb_middle', 'bb_lower', 'mfi', 'ema', 'atr', 'sar', 'obv']\n",
    "for i, name in enumerate(indicator_names):\n",
    "    normalized_indicators[name] = normalize_indicators(indicators[i])\n",
    "\n",
    "# Checking shapes\n",
    "for name in normalized_indicators:\n",
    "    print(f\"{name} shape: {normalized_indicators[name].shape}\")\n",
    "\n",
    "normalized_nsei=normalize_indicators(nsei_df['Close'].values)\n",
    "normalized_vix=normalize_indicators(vix_df['Close'].values)\n",
    "\n",
    "# Initialize parameters for model:\n",
    "\n",
    "D = len(Tickers)\n",
    "\n",
    "# state_dim = (14 technical indicators+ holdings)*D+ NSEI + VIX + balance + portfolio value:\n",
    "\n",
    "state_dim = 15 * D + 4  # (14 technical indicators+ holdings)*D+ \n",
    "action_dim = D * 3  # Actions: Buy, Sell, Hold for each ticker\n",
    "print(f\"Calculated state dimension: {state_dim}\")\n",
    "\n",
    "# Data into training and testing sets:\n",
    "train_df = stock_df.loc[start_train:end_train]\n",
    "test_df = stock_df.loc[start_test:end_test]\n",
    "train_nsei = nsei_df.loc[start_train:end_train]\n",
    "test_nsei = nsei_df.loc[start_test:end_test]\n",
    "train_vix = vix_df.loc[start_train:end_train]\n",
    "test_vix = vix_df.loc[start_test:end_test]\n",
    "\n",
    "\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(PPO, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.actor = nn.Linear(128, action_dim)  \n",
    "        self.critic = nn.Linear(128, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        action_probs = torch.softmax(self.actor(x), dim=-1)\n",
    "        state_value = self.critic(x)\n",
    "        return action_probs, state_value\n",
    "\n",
    "# Ensure proper initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def initialize_ppo_model(device):\n",
    "    \"\"\"\n",
    "    Initialize the PPO model, optimizer, and loss function.\n",
    "    \"\"\"\n",
    "    model = PPO(state_dim, action_dim).to(device)\n",
    "    model.apply(init_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    return model, optimizer, mse_loss\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def ppo_update(model, optimizer, mse_loss, memory, gamma, clip_epsilon, device, update_steps, batch_size):\n",
    "    for _ in range(update_steps):\n",
    "        if len(memory) < batch_size:\n",
    "            continue  # Skip if not enough samples\n",
    "\n",
    "        batch_indices = np.random.choice(len(memory), batch_size)\n",
    "        batch = [memory[i] for i in batch_indices]\n",
    "\n",
    "        states, actions, rewards, old_probs, next_states = zip(*batch)\n",
    "\n",
    "        states = torch.stack(states).to(device).float()\n",
    "        next_states = torch.stack(next_states).to(device).float()\n",
    "        actions = torch.tensor(actions).to(device).long()\n",
    "        old_probs = torch.tensor(old_probs).to(device).float()\n",
    "        rewards = torch.tensor(rewards).to(device).float().unsqueeze(-1)  # shape [B, 1]\n",
    "\n",
    "        new_probs, state_values = model(states)\n",
    "        _, next_state_values = model(next_states)\n",
    "\n",
    "        # Compute advantages\n",
    "        with torch.no_grad():\n",
    "            target_values = rewards + gamma * next_state_values\n",
    "            advantages = target_values - state_values\n",
    "\n",
    "        # Normalize advantages\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "        # Get new log probs of taken actions\n",
    "        new_probs = new_probs.gather(1, actions.unsqueeze(1))\n",
    "\n",
    "        # Compute ratio\n",
    "        ratio = new_probs / (old_probs.unsqueeze(-1) + 1e-8)\n",
    "        clipped_ratio = torch.clamp(ratio, 1 - clip_epsilon, 1 + clip_epsilon)\n",
    "\n",
    "        actor_loss = -torch.min(ratio * advantages, clipped_ratio * advantages).mean()\n",
    "        critic_loss = mse_loss(state_values, target_values)\n",
    "\n",
    "        loss = actor_loss + critic_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "'''    \n",
    "The advantage of PPO is its flexibility and robustness to different settings, so one can experiment with its hyperparameters to see what works best for each scenario.\n",
    "'''\n",
    "\n",
    "def train_ppo(train_df, episodes=250, gamma=0.997, epsilon=0.08, clip_epsilon=0.15, update_steps=20, batch_size=128, early_stop_threshold=0.002, patience=60, lr=0.0005):\n",
    "    \"\"\"\n",
    "    Trains a Proximal Policy Optimization (PPO) model for stock trading.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): DataFrame containing historical stock data.\n",
    "        episodes (int, optional): Number of training episodes. Defaults to 100.\n",
    "        gamma (float, optional): Discount factor for future rewards. Defaults to 0.99.\n",
    "        epsilon (float, optional): Probability of taking a random action. Defaults to 0.1.\n",
    "        clip_epsilon (float, optional): Clipping parameter for PPO. Defaults to 0.2.\n",
    "        update_steps (int, optional): Number of PPO update steps per batch. Defaults to 10.\n",
    "        batch_size (int, optional): Batch size for PPO updates. Defaults to 32.\n",
    "        early_stop_threshold (float, optional): Early stopping threshold for average reward improvement. Defaults to 0.001.\n",
    "        patience (int, optional): Number of episodes to wait for improvement before early stopping. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the final holdings, final portfolio value, list of tickers with buy or hold actions,\n",
    "               normalized final weights of tickers, and a DataFrame of final selected tickers and their weights.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = PPO(state_dim, action_dim).to(device)\n",
    "    model.apply(init_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    tickers_with_last_buy_or_hold = set()\n",
    "    total_iterations = 0\n",
    "\n",
    "    final_holdings = None\n",
    "    final_portfolio_value = None\n",
    "    rewards_history = []\n",
    "    portfolio_values_history = []\n",
    "    best_avg_reward = -float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        initial_holdings = np.zeros(D)\n",
    "        initial_balance = 100000\n",
    "        initial_portfolio_value = initial_balance + np.sum(train_df['Close'].iloc[0] * initial_holdings)\n",
    "        current_step = 0\n",
    "\n",
    "        holdings = initial_holdings.copy()\n",
    "        balance = initial_balance\n",
    "        portfolio_value = initial_portfolio_value\n",
    "\n",
    "        episode_rewards = []\n",
    "        memory = []\n",
    "\n",
    "        while current_step < len(train_df) - 1:\n",
    "            state_components = []\n",
    "            for i, ticker in enumerate(Tickers):\n",
    "                for name in indicator_names:\n",
    "                    state_components.append(normalized_indicators[name][i, current_step])\n",
    "            state_components.extend([normalized_nsei[current_step, 0], normalized_vix[current_step, 0]])\n",
    "            state_components.extend(holdings)\n",
    "            state_components.extend([balance, portfolio_value])\n",
    "            state = torch.FloatTensor(state_components).float().to(device)\n",
    "\n",
    "            action_probs, state_value = model(state)\n",
    "\n",
    "            if torch.isnan(action_probs).any() or torch.isinf(action_probs).any():\n",
    "                raise ValueError(\"NaNs or Infs found in action probabilities\")\n",
    "\n",
    "            if random.random() < epsilon:\n",
    "                action = random.randint(0, action_dim - 1)\n",
    "            else:\n",
    "                action = torch.argmax(action_probs).item()\n",
    "\n",
    "            action_type = action % 3\n",
    "            ticker_idx = action // 3\n",
    "            action_desc = ['hold', 'buy', 'sell'][action_type]\n",
    "\n",
    "            if action_desc in ['buy', 'hold']:\n",
    "                tickers_with_last_buy_or_hold.add(Tickers[ticker_idx])\n",
    "            else:\n",
    "                tickers_with_last_buy_or_hold.discard(Tickers[ticker_idx])\n",
    "\n",
    "            next_prices = train_df['Close'].iloc[current_step + 1]\n",
    "            next_portfolio_value = balance + np.sum(next_prices * holdings)\n",
    "\n",
    "            max_shares = 3\n",
    "            price = next_prices.iloc[ticker_idx]\n",
    "            if action_desc == 'buy' and balance >= price:\n",
    "                shares = 1\n",
    "                holdings[ticker_idx] += shares\n",
    "                balance -= shares * price\n",
    "            elif action_desc == 'sell' and holdings[ticker_idx] > 0:\n",
    "                shares = min(holdings[ticker_idx], max_shares)\n",
    "                holdings[ticker_idx] -= shares\n",
    "                balance += shares * price\n",
    "\n",
    "\n",
    "            transaction_cost = 0.0002  # ~0.02% penalty\n",
    "            drawdown = max(0, (portfolio_value - next_portfolio_value) / portfolio_value)\n",
    "            reward = (next_portfolio_value - portfolio_value) / portfolio_value\n",
    "            reward -= transaction_cost * (action_type != 0)\n",
    "            reward -= 0.005 * drawdown  # penalize sharp drops\n",
    "            # portfolio_volatility = np.std(holdings * train_df['Close'].pct_change().iloc[current_step])\n",
    "            # reward -= 0.01 * portfolio_volatility\n",
    "            episode_rewards.append(reward)\n",
    "            portfolio_value = next_portfolio_value\n",
    "\n",
    "            next_state_components = []\n",
    "            for i, ticker in enumerate(Tickers):\n",
    "                for name in indicator_names:\n",
    "                    next_state_components.append(normalized_indicators[name][i, current_step + 1])\n",
    "            next_state_components.extend([normalized_nsei[current_step + 1, 0], normalized_vix[current_step + 1, 0]])\n",
    "            next_state_components.extend(holdings)\n",
    "            next_state_components.extend([balance, portfolio_value])\n",
    "            next_state = torch.FloatTensor(next_state_components).float().to(device)\n",
    "\n",
    "            _, next_state_value = model(next_state)\n",
    "            advantage = reward + gamma * next_state_value.item() - state_value.item()\n",
    "            target_value = torch.FloatTensor([reward + gamma * next_state_value.item() + 1e-8]).to(device).view_as(state_value)\n",
    "            critic_loss = mse_loss(state_value, target_value)\n",
    "            actor_loss = -torch.log(action_probs[action] + 1e-8) * advantage\n",
    "            loss = actor_loss + critic_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            memory.append((state, action, reward, action_probs[action].item(), next_state))\n",
    "            current_step += 1\n",
    "\n",
    "            if len(memory) >= 128:\n",
    "                ppo_update(model, optimizer, mse_loss, memory, gamma, clip_epsilon, device, update_steps, batch_size)\n",
    "                memory = []\n",
    "\n",
    "        final_holdings = holdings\n",
    "        final_portfolio_value = portfolio_value\n",
    "        total_reward = np.sum(episode_rewards)\n",
    "        rewards_history.append(total_reward)\n",
    "        portfolio_values_history.append(portfolio_value)\n",
    "\n",
    "        avg_reward = np.mean(rewards_history[-patience:])\n",
    "        print(f\"Episode {episode+1}/{episodes}, Reward: {total_reward}, Avg Reward: {avg_reward}\")\n",
    "\n",
    "        if avg_reward > best_avg_reward + early_stop_threshold:\n",
    "            best_avg_reward = avg_reward\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at episode {episode+1}\")\n",
    "            break\n",
    "\n",
    "    tickers_list = list(tickers_with_last_buy_or_hold)\n",
    "    print(f\"Tickers with 'buy' or 'hold' actions at the end of the last iteration: {tickers_with_last_buy_or_hold}\")\n",
    "    print(\"Final portfolio value:\", final_portfolio_value)\n",
    "    print(\"Final holdings:\")\n",
    "    for i, ticker in enumerate(Tickers):\n",
    "        print(f\"{ticker} holdings: {final_holdings[i]}\")\n",
    "\n",
    "    weights = final_holdings * train_df['Close'].iloc[-1]\n",
    "    total_weights = np.sum(weights)\n",
    "    normalized_weights = weights / total_weights\n",
    "\n",
    "    final_weights_df = pd.DataFrame({\n",
    "        'Ticker': Tickers,\n",
    "        'Weight': normalized_weights\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(rewards_history, label='Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Reward History')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(portfolio_values_history, label='Portfolio Value')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Portfolio Value')\n",
    "    plt.title('Portfolio Values History')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return final_holdings, final_portfolio_value, tickers_list, normalized_weights, final_weights_df\n",
    "\n",
    "\n",
    "# Train the PPO model\n",
    "final_holdings, final_portfolio_value, tickers_list, normalized_weights, final_weights_df = train_ppo(train_df )\n",
    "\n",
    "# Display results\n",
    "print(\"Best Holdings:\", final_holdings)\n",
    "print(\"Best Portfolio Value:\", final_portfolio_value)\n",
    "print(\"Tickers with Last Buy or Hold:\", tickers_list)\n",
    "print(\"Best Weights:\", normalized_weights)\n",
    "\n",
    "\n",
    "# Define comparison portfolios:\n",
    "\n",
    "def calculate_cvar(returns, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Calculates the Conditional Value at Risk (CVaR) of a portfolio.\n",
    "\n",
    "    Args:\n",
    "        returns (np.ndarray): Array of portfolio returns.\n",
    "        confidence_level (float, optional): Confidence level for VaR calculation. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        float: The Conditional Value at Risk (CVaR) of the portfolio.\n",
    "    \"\"\"\n",
    "    # Calculate VaR\n",
    "    var = np.percentile(returns, 100 * (1 - confidence_level))\n",
    "\n",
    "    # Calculate CVaR\n",
    "    cvar = returns[returns <= var].mean()\n",
    "\n",
    "    return cvar\n",
    "\n",
    "# Define mean conditional value-at-risk algorithm:\n",
    "\n",
    "def mCVAR_optimization(returns, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Optimizes the portfolio weights to minimize Mean Conditional Value at Risk (mCVaR).\n",
    "\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame containing historical stock returns.\n",
    "        confidence_level (float, optional): Confidence level for VaR calculation. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Optimal portfolio weights that minimize mCVaR.\n",
    "    \"\"\"\n",
    "    tickers = returns.columns\n",
    "    n_tickers = len(tickers)\n",
    "\n",
    "    # Objective function to minimize mCVaR\n",
    "    def objective(weights):\n",
    "        portfolio_returns = returns.dot(weights)\n",
    "        return calculate_cvar(portfolio_returns, confidence_level)\n",
    "\n",
    "    # Constraints: Weights sum to 1\n",
    "    constraints = ({\n",
    "        'type': 'eq',\n",
    "        'fun': lambda weights: np.sum(weights) - 1\n",
    "    })\n",
    "\n",
    "    # Bounds: Weights between 0 and 1\n",
    "    bounds = [(0, 1)] * n_tickers\n",
    "\n",
    "    # Initial guess for weights (equal distribution)\n",
    "    initial_weights = np.ones(n_tickers) / n_tickers\n",
    "\n",
    "    # Minimize the objective function\n",
    "    result = minimize(objective, initial_weights, bounds=bounds, constraints=constraints)\n",
    "\n",
    "    return result.x\n",
    "\n",
    "\n",
    "# Definie Hierarchical Risk Parity algorithm:\n",
    "\n",
    "def get_IVP(cov, **kargs):\n",
    "    ivp = 1. / np.diag(cov)\n",
    "    ivp /= ivp.sum()\n",
    "    return ivp\n",
    "\n",
    "def get_cluster_var(cov, cItems):\n",
    "    cov_ = cov.loc[cItems, cItems]\n",
    "    w_ = get_IVP(cov_).reshape(-1, 1)\n",
    "    cVar = np.dot(np.dot(w_.T, cov_), w_)[0, 0]\n",
    "    return cVar\n",
    "\n",
    "def get_quasi_diag(link):\n",
    "    link = link.astype(int)\n",
    "    sortIx = pd.Series([link[-1, 0], link[-1, 1]])\n",
    "    numItems = link[-1, 3]\n",
    "    while sortIx.max() >= numItems:\n",
    "        sortIx.index = range(0, sortIx.shape[0] * 2, 2)\n",
    "        df0 = sortIx[sortIx >= numItems]\n",
    "        i = df0.index\n",
    "        j = df0.values - numItems\n",
    "        sortIx[i] = link[j, 0]\n",
    "        df0 = pd.Series(link[j, 1], index=i + 1)\n",
    "        sortIx = pd.concat([sortIx, df0])\n",
    "        sortIx = sortIx.sort_index()\n",
    "        sortIx.index = range(sortIx.shape[0])\n",
    "    return sortIx.tolist()\n",
    "\n",
    "def get_rec_bipart(cov, sortIx):\n",
    "    w = pd.Series(1.0, index=sortIx)  # Ensure w is of float type\n",
    "    cItems = [sortIx]\n",
    "    while len(cItems) > 0:\n",
    "        cItems = [i[int(j):int(k)] for i in cItems for j, k in ((0, len(i) / 2), (len(i) / 2, len(i))) if len(i) > 1]\n",
    "        for i in range(0, len(cItems), 2):\n",
    "            cItems0 = cItems[i]\n",
    "            cItems1 = cItems[i + 1]\n",
    "            cVar0 = get_cluster_var(cov, cItems0)\n",
    "            cVar1 = get_cluster_var(cov, cItems1)\n",
    "            alpha = float(1 - cVar0 / (cVar0 + cVar1))  # Explicitly cast alpha to float\n",
    "            w[cItems0] *= alpha\n",
    "            w[cItems1] *= 1 - alpha\n",
    "    return w\n",
    "\n",
    "def HRP_Allocation(returns):\n",
    "    cov = returns.cov()\n",
    "    corr = returns.corr()\n",
    "    dist = squareform(((1 - corr) / 2.)**.5)\n",
    "    link = linkage(dist, 'single')\n",
    "    sortIx = get_quasi_diag(link)\n",
    "    sortIx = returns.columns[sortIx].tolist()\n",
    "    hrp = get_rec_bipart(cov, sortIx)\n",
    "    return hrp.sort_index()\n",
    "\n",
    "# Mean variance optimization (MVO) algorithm:\n",
    "\n",
    "def optimize_portfolio(returns):\n",
    "    mean_returns = returns.mean()\n",
    "    cov_matrix = returns.cov()\n",
    "\n",
    "    def portfolio_performance(weights):\n",
    "        portfolio_returns = np.dot(weights, mean_returns)\n",
    "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return portfolio_returns, portfolio_volatility\n",
    "\n",
    "    def negative_sharpe_ratio(weights, risk_free_rate=0):\n",
    "        p_returns, p_volatility = portfolio_performance(weights)\n",
    "        return - (p_returns - risk_free_rate) / p_volatility\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "    bounds = tuple((0, 1) for _ in range(returns.shape[1]))\n",
    "    initial_guess = returns.shape[1] * [1. / returns.shape[1]]\n",
    "\n",
    "    optimized_result = minimize(negative_sharpe_ratio, initial_guess,\n",
    "                                method='SLSQP', bounds=bounds,\n",
    "                                constraints=constraints)\n",
    "\n",
    "    return optimized_result.x\n",
    "\n",
    "\n",
    "# Display the head of train and test returns dataframes\n",
    "# print(\"Train Returns:\")\n",
    "# # print(train_returns.head())\n",
    "\n",
    "# print(\"\\nTest Returns:\")\n",
    "# # print(test_returns.head())\n",
    "\n",
    "\n",
    "# Function to calculate portfolio returns:\n",
    "def calculate_portfolio_returns(weights, test_returns):\n",
    "    portfolio_returns = (weights * test_returns).sum(axis=1)\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()-1\n",
    "    return cumulative_returns\n",
    "\n",
    "# Align indices of returns with stock_df data:\n",
    "returns_df = returns.reindex(stock_df.index)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "# train_df, test_df = train_test_split(stock_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Get the indices for train and test data\n",
    "train_indices = train_df.index\n",
    "test_indices = test_df.index\n",
    "\n",
    "# Filter the returns dataframe using the train and test indices\n",
    "train_returns = returns_df.loc[start_train:end_train]\n",
    "test_returns = returns_df.loc[start_test:end_test]\n",
    "\n",
    "train_returns = train_returns.dropna(axis=0, how='any')\n",
    "test_returns = test_returns.dropna(axis=0, how='any')\n",
    "\n",
    "# Display the head of the correctly split train and test returns dataframes\n",
    "print(\"\\nTrain Returns (using manual dates):\")\n",
    "print(train_returns.head())\n",
    "print(f\"Shape: {train_returns.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\nTest Returns (using manual dates):\")\n",
    "print(test_returns.head())\n",
    "print(f\"Shape: {test_returns.shape}\")\n",
    "\n",
    "# Filter the test returns to include only the selected tickers returned by PPO model:\n",
    "\n",
    "selected_tickers = final_weights_df['Ticker']\n",
    "test_returns_filtered = test_returns[selected_tickers]\n",
    "\n",
    "# Convert the weights to a numpy array\n",
    "drl_weights = final_weights_df['Weight'].values\n",
    "\n",
    "# Calculate the portfolio returns on the test data\n",
    "drl_portfolio_returns = test_returns_filtered.dot(drl_weights)\n",
    "\n",
    "# Calculate cumulative returns for the portfolio\n",
    "drl_cumulative_returns = (1 + drl_portfolio_returns).cumprod() - 1\n",
    "\n",
    "# Display the portfolio returns and cumulative returns\n",
    "print(\"DRL Portfolio Returns on Test Data:\")\n",
    "print(drl_portfolio_returns.head())\n",
    "\n",
    "print(\"\\nDRL Cumulative Returns on Test Data:\")\n",
    "print(drl_cumulative_returns.head())\n",
    "\n",
    "# MVO portfolio on test data:\n",
    "\n",
    "# Optimize portfolio using train returns:\n",
    "mvo_weights = optimize_portfolio(train_returns)\n",
    "print(mvo_weights)\n",
    "mvo_portfolio_returns = test_returns.dot(mvo_weights)\n",
    "mvo_cumulative_returns = calculate_portfolio_returns(mvo_weights, test_returns)\n",
    "\n",
    "# HRP portfolio on test data:\n",
    "\n",
    "hrp_weights = HRP_Allocation(train_returns)\n",
    "\n",
    "print(\"HRP train weights:\\n\")\n",
    "print(hrp_weights)\n",
    "print()\n",
    "\n",
    "hrp_portfolio_returns = test_returns.dot(hrp_weights)\n",
    "hrp_cumulative_returns = calculate_portfolio_returns(hrp_weights, test_returns)\n",
    "\n",
    "# MCVAR portfolio on test data:\n",
    "mcvar_weights = mCVAR_optimization(train_returns)\n",
    "print(\" mCVAR Optimal Portfolio Weights:\", mcvar_weights)\n",
    "mcvar_portfolio_returns = test_returns.dot(mcvar_weights)\n",
    "mcvar_cumulative_returns = calculate_portfolio_returns(mcvar_weights, test_returns)\n",
    "\n",
    "# Create DataFrames to compare HRP , MVO and DRL  performance:\n",
    "\n",
    "performance_df = pd.DataFrame({\n",
    "    'DRL Cumulative Returns': drl_cumulative_returns,\n",
    "    'MVO Cumulative Returns': mvo_cumulative_returns,\n",
    "    'HRP Cumulative Returns': hrp_cumulative_returns,\n",
    "    'mCVAR Cumulative Returns': mcvar_cumulative_returns\n",
    "})\n",
    "\n",
    "print(\"Performance Comparison:\\n\", performance_df)\n",
    "\n",
    "# Plot the performance:\n",
    "performance_df.plot(title=\"DRL vs HRP vs MVO vs mCVAR Performance\")\n",
    "\n",
    "\n",
    "mvo_last_cumulative_return = mvo_cumulative_returns.iloc[-1]\n",
    "hrp_last_cumulative_return = hrp_cumulative_returns.iloc[-1]\n",
    "drl_last_cumulative_return = drl_cumulative_returns.iloc[-1]\n",
    "mcvar_last_cumulative_return = mcvar_cumulative_returns.iloc[-1]\n",
    "\n",
    "last_cumul = {\n",
    "    'cumulative_returns[-1]': [\n",
    "        mvo_last_cumulative_return,\n",
    "        hrp_last_cumulative_return,\n",
    "        drl_last_cumulative_return,\n",
    "        mcvar_last_cumulative_return\n",
    "    ]\n",
    "}\n",
    "\n",
    "port_names = ['MVO', 'HRP', 'DRL', 'mCVAR']\n",
    "\n",
    "cumul_df = pd.DataFrame(last_cumul, index=port_names)\n",
    "\n",
    "print(cumul_df)\n",
    "\n",
    "\n",
    "# Use quantstats to define the function to calculate performance metrics :\n",
    "\n",
    "# Existing portfolio data\n",
    "portfolios = {\n",
    "    \"MVO Portfolio\": mvo_portfolio_returns,\n",
    "    \"HRP Portfolio\": hrp_portfolio_returns,\n",
    "    \"DRL Portfolio\": drl_portfolio_returns,\n",
    "    \"mCVAR Portfolio\": mcvar_portfolio_returns\n",
    "}\n",
    "\n",
    "# List of metrics to store\n",
    "metrics = ['Sharpe Ratio', 'Omega Ratio', 'Volatility', 'Max Drawdown', 'Sortino Ratio', 'Calmar Ratio', 'Tail Ratio', 'Risk Return', 'Skew', 'Kurtosis']\n",
    "\n",
    "# Create an empty dictionary to store the metrics\n",
    "metrics_data = {'Metrics': metrics}\n",
    "\n",
    "# Initialize risk-free rate\n",
    "risk_free_rate = 0.0419\n",
    "\n",
    "# Function to calculate performance metrics:\n",
    "\n",
    "def calculate_performance_metrics(returns, risk_free_rate=0.0):\n",
    "    returns_series = pd.Series(returns).dropna()\n",
    "    \n",
    "    # Fix: Make sure returns are properly formatted for quantstats functions\n",
    "    sharpe_ratio = qs.stats.sharpe(returns_series, rf=risk_free_rate, periods=252, annualize=True)\n",
    "    \n",
    "    # Fix: For omega ratio, convert Series to numeric values if needed\n",
    "    try:\n",
    "        # Pass the Series directly instead of converting to DataFrame\n",
    "        omega_ratio = qs.stats.omega(returns_series, required_return=0.0, rf=risk_free_rate, periods=252)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating Omega ratio: {e}\")\n",
    "        omega_ratio = None\n",
    "        \n",
    "    volatility = qs.stats.volatility(returns_series, periods=252, annualize=True)\n",
    "    max_drawdown = qs.stats.max_drawdown(returns_series)\n",
    "    sortino_ratio = qs.stats.sortino(returns_series, rf=risk_free_rate, periods=252)\n",
    "    \n",
    "    # Fix: For functions that use prepare_returns, set it to False since we're already passing returns\n",
    "    calmar_ratio = qs.stats.calmar(returns_series)\n",
    "    tail_ratio = qs.stats.tail_ratio(returns_series, cutoff=0.95)\n",
    "    risk_return = qs.stats.risk_return_ratio(returns_series)\n",
    "    skew = qs.stats.skew(returns_series)\n",
    "    kurtosis = qs.stats.kurtosis(returns_series)\n",
    "\n",
    "    return {\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Omega Ratio': omega_ratio,\n",
    "        'Volatility': volatility,\n",
    "        'Max Drawdown': max_drawdown,\n",
    "        'Sortino Ratio': sortino_ratio,\n",
    "        'Calmar Ratio': calmar_ratio,\n",
    "        'Tail Ratio': tail_ratio,\n",
    "        'Risk Return': risk_return,\n",
    "        'Skew': skew,\n",
    "        'Kurtosis': kurtosis\n",
    "    }\n",
    "\n",
    "# Calculate metrics for each portfolio and store in the dictionary:\n",
    "\n",
    "for name, returns in portfolios.items():\n",
    "    print(f\"\\nPerformance Metrics for {name}:\")\n",
    "    performance_metrics = calculate_performance_metrics(returns, risk_free_rate)\n",
    "    metrics_data[name] = [performance_metrics[metric] for metric in metrics]\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.set_index('Metrics', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_portfolio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
